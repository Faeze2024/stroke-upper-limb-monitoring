# ğŸ§  Stroke Upper Limb Monitoring

A computer vision-based tool to monitor and analyze upper limb movements in post-stroke patients, built with Python and MediaPipe BlazePose.

---

## ğŸ“Œ About this project

Stroke survivors often suffer from limited range of motion in their upper limbs.\
This project aims to automatically detect and track key joint angles (shoulder, elbow, wrist) during rehabilitation exercises, helping clinicians and researchers analyze movement quality over time.

We extract joint coordinates from live webcam or images, calculate angles, store them, and visualize motion data in real time.\
Additionally, the tool can compare actual patient motion data against a predefined reference pattern to track progress.

---

## âœ¨ Features

- Live tracking of upper limb keypoints (shoulder, elbow, wrist)
- Calculation and storage of joint angles over time
- Real-time plotting of joint angles
- Comparison against reference movement curves
- Simple Python interface for extending or customizing

---

## âš™ï¸ Installation

Clone the repository:

```bash
git clone https://github.com/YourUsername/stroke-upper-limb-monitoring.git
cd stroke-upper-limb-monitoring
```

Install the required packages:

```bash
pip install -r requirements.txt
```

---


---

âš™ï¸ How to Activate the Virtual Environment (Windows)

In this project folder, there is a prepared script named activate_venv.bat.

To activate the Python virtual environment, simply double-click on this file.

ğŸ“¦ Steps to set up and activate:

If you have not created the virtual environment yet, open PowerShell or CMD in your project folder and run:

python -m venv venv

This will create a venv folder containing the virtual environment.

Activate the virtual environment:

Just double-click on:

activate_venv.bat

You should see your terminal prompt change to something like (venv) indicating the environment is active.

âŒ To deactivate:

Simply type:

deactivate

âœ… Notes:

The activate_venv.bat file automatically sets the correct execution policy and then runs activate_venv.ps1.

If you move or rename your venv folder, update the script accordingly.

This makes it super easy to activate your environment without needing to manually type commands every time!


## ğŸš€ How to use

Run the main script to start capturing and analyzing movements:

```bash
python main.py
```

By default, it:

- Captures from webcam
- Detects keypoints
- Calculates angles
- Saves data as CSV
- Draws live plot of angles vs time

---

## ğŸ“Š Output

- CSV file with timestamps and calculated joint angles
- Real-time matplotlib chart of movement
- Optional comparison with predefined reference curves for analysis

---

## ğŸ›  Project structure

```
stroke-upper-limb-monitoring/
â”œâ”€â”€ data/                # Saved CSV files
â”œâ”€â”€ plots/               # Generated plots
â”œâ”€â”€ src/                 # Python scripts and modules
â”‚   â”œâ”€â”€ pose_estimation.py
â”‚   â”œâ”€â”€ angle_calculation.py
â”‚   â””â”€â”€ plotting.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```
---

## âœ… TODO

- Add GUI or web dashboard for easier use
- Support for full upper body keypoints
- Save and compare sessions per user/patient
- Generate PDF reports for therapists
- Export data in common formats (Excel, JSON)

---

## ğŸ¤– Built with

- Python
- MediaPipe BlazePose
- OpenCV
- NumPy
- Matplotlib

---

## ğŸ“ License

This project is licensed under the MIT License.

---

If you like this project, feel free to â­ï¸ the repo or contribute!

